{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Anatomy of a script\n",
    "- Virtual environment, requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple concordance function (KWIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regex\n",
    "import string #regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It was the best of times, it was the worst of times\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'was',\n",
       " 'the',\n",
       " 'best',\n",
       " 'of',\n",
       " 'times,',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'worst',\n",
       " 'of',\n",
       " 'times']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick regex tokenizer for splitting strings\n",
    "def tokenize(input_string):\n",
    "    # Split on any non-alphanumeric character\n",
    "    tokenizer = re.compile(r\"\\W+\")\n",
    "    # Tokenize\n",
    "    token_list = tokenizer.split(input_string)\n",
    "    # Return token_list\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'was',\n",
       " 'the',\n",
       " 'best',\n",
       " 'of',\n",
       " 'times',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'worst',\n",
       " 'of',\n",
       " 'times']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"The worldâ€™s biggest oil companies are no stranger to UK waters, but by the end of the decade they will be running more offshore wind turbines than oil rigs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'world',\n",
       " 's',\n",
       " 'biggest',\n",
       " 'oil',\n",
       " 'companies',\n",
       " 'are',\n",
       " 'no',\n",
       " 'stranger',\n",
       " 'to',\n",
       " 'UK',\n",
       " 'waters',\n",
       " 'but',\n",
       " 'by',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'the',\n",
       " 'decade',\n",
       " 'they',\n",
       " 'will',\n",
       " 'be',\n",
       " 'running',\n",
       " 'more',\n",
       " 'offshore',\n",
       " 'wind',\n",
       " 'turbines',\n",
       " 'than',\n",
       " 'oil',\n",
       " 'rigs',\n",
       " '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code along task: Creating a KWIC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kwic(text, keyword, window_size=50):\n",
    "    # For all regex matches\n",
    "    for match in re.finditer(keyword, text):\n",
    "        # first character index of match\n",
    "        word_start = match.start()\n",
    "        # last character index of match\n",
    "        word_end = match.end()\n",
    "        \n",
    "        # Left window\n",
    "        left_window_start = max(0, word_start-window_size)\n",
    "        left_window = text[left_window_start:word_start]\n",
    "        \n",
    "        # Right window\n",
    "        right_window_end = word_end + window_size\n",
    "        right_window = text[word_end : right_window_end]\n",
    "        \n",
    "        # print line\n",
    "        line = f\"{left_window} {keyword} {right_window}\"\n",
    "        \n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../data/imgs/expected-vs-observed.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For reference, see http://collocations.de/AM/index.html__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "u = our keyword <br>\n",
    "v = a collocate <br>\n",
    "\n",
    "O11 = our keyword && our collocate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../data/imgs/mi.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- u = how often keyword occurs\n",
    "- v = how often collocate appears along with u\n",
    "- O11 = v & u \n",
    "- O21 = v & !u\n",
    "- etc\n",
    "- N = total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in corpus:\n",
    "    # Calculate each of these\n",
    "    u =\n",
    "    v = \n",
    "    \n",
    "    R1 = \n",
    "    C1 = \n",
    "    \n",
    "    # length of text\n",
    "    N = len()\n",
    "    \n",
    "    # Expected\n",
    "    E11 = (R1*C1/N)\n",
    "\n",
    "    # return MI\n",
    "    MI = log(O11/E1l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang101",
   "language": "python",
   "name": "lang101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}