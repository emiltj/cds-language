{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "lang101",
   "display_name": "lang101",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "String processing with Python\n",
    "\n",
    "Using a text corpus found on the cds-language GitHub repo or a corpus of your own found on a site such as Kaggle, write a Python script which calculates collocates for a specific keyword.\n",
    "\n",
    "\n",
    "\n",
    "The script should take a directory of text files, a keyword, and a window size (number of words) as input parameters, and an output file called out/{filename}.csv\n",
    "These parameters can be defined in the script itself\n",
    "Find out how often each word collocates with the target across the corpus\n",
    "Use this to calculate mutual information between the target word and all collocates across the corpus\n",
    "Save result as a single file consisting of four columns: collocate, raw_frequency, MI\n",
    "\n",
    "\n",
    "BONUS CHALLENGE: Use argparse to take inputs from the command line as parameters\n",
    "\n",
    "\n",
    "General instructions\n",
    "\n",
    "For this assignment, you should upload a standalone .py script which can be executed from the command line.\n",
    "Save your script as collocation.py\n",
    "Make sure to include a requirements.txt file and your data\n",
    "You can either upload the scripts here or push to GitHub and include a link - or both!\n",
    "Your code should be clearly documented in a way that allows others to easily follow the structure of your script and to use them from the command line\n",
    "\n",
    "\n",
    "Purpose\n",
    "\n",
    "This assignment is designed to test that you have a understanding of:\n",
    "\n",
    "how to structure, document, and share a Python scripts;\n",
    "how to effectively make use of native Python packages for string processing;\n",
    "how to extract basic linguistic information from large quantities of text, specifically in relation to a specific target keyword"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary modules\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "filepath = os.path.join(\"..\", \"data\", \"100_english_novels\", \"corpus\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function which includes the arguments text directory, keyword and window size (the latter n-words before and n-words after keyword)\n",
    "def collocation(text_dir, keyword, window_size = 1):\n",
    "    # Make a list that the loop appends to\n",
    "    collocations = list()\n",
    "    collocations_unique = list()\n",
    "    concordance_lines = list()\n",
    "    collocate_lines = list()\n",
    "\n",
    "    # For each file in the filepath that ends with .txt, read the file into \"text\"\n",
    "    for file in Path(text_dir).glob(\"*9.txt\"):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "            # Tokenize each text into individual words\n",
    "            text_tokens = re.compile(r\"\\W+\").split(text)\n",
    "            \n",
    "            # Return index for each element text_tokens if the element in text_tokens is equal to keyword\n",
    "            indices = [index for index, match in enumerate(text_tokens) if match == keyword]\n",
    "            \n",
    "            # For each keyword in the text, create an object (= concordance_line) that has keyword and the words just before and after (keyword +- window_size)\n",
    "            for index in indices:\n",
    "                concordance_line = text_tokens[max(0,index - window_size):index+window_size+1]\n",
    "                \n",
    "                # Append the concordance line to \"concordance_lines\"\n",
    "                concordance_lines.append(concordance_line)\n",
    "\n",
    "                # For each word in the concordance_line, add it to \"new_collocations\" if it is not the keyword.\n",
    "                new_collocations = [collocate for collocate in concordance_line if collocate != keyword]\n",
    "\n",
    "                # For each word in the concordance_line, add it to \"new_collocations_unique\" if it is not the keyword and if it does not already exist in the list.\n",
    "                new_collocations_unique = [collocate for collocate in concordance_line if collocate not in collocations_unique and collocate != keyword]\n",
    "                \n",
    "                # Extend my list collocations, with all the collocations (words around keyword)\n",
    "                collocations.extend(new_collocations)\n",
    "                \n",
    "                # Extend my list collocations_unique, with all the collocations (words around keyword) that do not already appear in the list.\n",
    "                if new_collocations_unique not in collocations_unique:\n",
    "                    collocations_unique.extend(new_collocations_unique)\n",
    "\n",
    "    \n",
    "    # Go through the collocations (all words that have appeared with the keyword in any of the texts) and count how often they have occured with the keyword.\n",
    "    o11 = Counter(collocations)\n",
    "\n",
    "    # Create an empty dictionary for counting concordance lines where keyword occurs without collocation.\n",
    "    o12 = dict()\n",
    "    \n",
    "    # For each unique collocation in collocations_unique:\n",
    "    for collocation_unique in collocations_unique:\n",
    "        \n",
    "        # Set loop counter\n",
    "        loop_count = 0\n",
    "        \n",
    "        # For each line in concordance_lines, if the unique collocation does NOT appear, add +1 to counter\n",
    "        for concordance_line in concordance_lines:\n",
    "            if collocation_unique not in concordance_line:\n",
    "                loop_count += 1\n",
    "\n",
    "        # Updating the o12 to include a count for n-times that each unique collocation did not appear with a keyword\n",
    "        o12.update({collocation_unique : loop_count})\n",
    "    \n",
    "    # Getting number of concordance lines (and we have 1 per keyword)\n",
    "    n_times_keyword = len(concordance_lines)\n",
    "    \n",
    "    # Writing a dictionary with the keys for all collocates, and the value for n_keywords.\n",
    "    R1 = {x: n_times_keyword for x in o12}\n",
    "\n",
    "\n",
    "    print(f\"All concordance lines with keyword: {concordance_lines}\")\n",
    "    print(f\"All collocations (not unique): {collocations}\")\n",
    "    print(f\"All unique collocations: {collocations_unique}\")\n",
    "    print(f\"Number of collocations: {len(collocations)}\")\n",
    "    print(f\"Number of unique collocations: {len(collocations_unique)}\")\n",
    "    print(f\"N-times keyword occurs with collocate: {o11}\") # n-times keyword occurs with collocate\n",
    "    print(f\"n-times keyword occurs w/o collocate: {o12}\") # n-times keyword occurs w/o collocate\n",
    "    print(f\"N-times keyword occurs (regardless of collocate): {R1}\") # n-times keyword occurs (regardless of collocate)\n",
    "    \n",
    "######################## STILL MISSING (HAVEN'T DONE THIS YET) ########################\n",
    "            # o21 # n-times collocate occurs w/o keyword\n",
    "            # o22 # n-times neither keyword nor collocate appears within a 1 + window_size\n",
    "            # R2 # n-times a window contains collocate w/o keyword, or neither contains keyword nor collocate\n",
    "            # C1 # n-times collocate occurs either with or without keyword\n",
    "            # C2 # n-times collocate does not occur\n",
    "            # N # sum of C1 + C2 + R1 + R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All concordance lines with keyword: [['to', 'denounce', 'the'], ['would', 'denounce', 'me'], ['would', 'denounce', 'them'], ['to', 'denounce', 'my']]\nAll collocations (not unique): ['to', 'the', 'would', 'me', 'would', 'them', 'to', 'my']\nAll unique collocations: ['to', 'the', 'would', 'me', 'them', 'my']\nNumber of collocations: 8\nNumber of unique collocations: 6\nN-times keyword occurs with collocate: Counter({'to': 2, 'would': 2, 'the': 1, 'me': 1, 'them': 1, 'my': 1})\nn-times keyword occurs w/o collocate: {'to': 2, 'the': 3, 'would': 2, 'me': 3, 'them': 3, 'my': 3}\nN-times keyword occurs (regardless of collocate): {'to': 4, 'the': 4, 'would': 4, 'me': 4, 'them': 4, 'my': 4}\n"
     ]
    }
   ],
   "source": [
    "collocation(filepath, \"denounce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}